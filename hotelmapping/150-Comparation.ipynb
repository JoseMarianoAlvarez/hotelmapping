{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import strip_accents_ascii, strip_accents_unicode\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os \n",
    "import jellyfish as jf\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "numcores = 16\n",
    "tiene_gpu = False\n",
    "pd.set_option('display.max_columns', 99)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este es el root en el servidor de jupyter\n",
    "data_root = 'C:/code/hotelmapping/data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_candidates_file = os.path.join(data_root, 'travcoding/pair_candidates.parquet')\n",
    "inventory_clean_file = os.path.join(data_root, 'travcoding/properties_clean.parquet')                                               \n",
    "providers_clean_file = os.path.join(data_root, 'travcoding/Providers_clean.parquet')\n",
    "\n",
    "# Cargo los archivos\n",
    "inventory_ddf = dd.read_parquet(inventory_clean_file, engine='pyarrow').repartition(numcores)\n",
    "provider_ddf  = dd.read_parquet(providers_clean_file, engine='pyarrow').repartition(numcores)\n",
    "candidates_ddf = dd.read_parquet(pair_candidates_file, engine='pyarrow').repartition(numcores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523935"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inventory_clean_file\n",
    "inventory_ddf.index.size.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703021"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provider_ddf.index.size.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291923"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_ddf.index.size.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = candidates_ddf.merge(inventory_ddf, how='inner', left_on=['PropertyId'], right_index=True)\\\n",
    "    .merge(provider_ddf, how='inner', left_on=['PropertyByProviderId'], right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['PropertyId',\n",
    "    'providerid',\n",
    "    'PropertyByProviderId',\n",
    "    'idf_count',\n",
    "    'idf_sum',\n",
    "    'idf_max',\n",
    "    'idf_mean',\n",
    "    #---------------------------------------\n",
    "    #'countrycode_x',\n",
    "    #'countrycode_y',\n",
    "    'countrycorregido_x',\n",
    "    'countrycorregido_y',\n",
    "    'propertytype_x',\n",
    "    'propertytype_y',\n",
    "    'propertyname_x',\n",
    "    'propertyname_y',\n",
    "    'lat_x',\n",
    "    'lat_y',\n",
    "    'lng_x',\n",
    "    'lng_y',\n",
    "    'address_x',\n",
    "    'address_y',\n",
    "    'zipcode_y',\n",
    "    'zipcode_x',\n",
    "    'city_x',\n",
    "    'city_y',\n",
    "    'state_y',\n",
    "    'state_x',\n",
    "    'starrating_y',\n",
    "    'starrating_x',\n",
    "    'email_x',\n",
    "    'email_y',\n",
    "    'phone_x',\n",
    "    'phone_y',\n",
    "    'fax_y',\n",
    "    'fax_x',\n",
    "    'website_x',\n",
    "    'website_y'    \n",
    "    # 'propertyid',\n",
    "    #'language'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance in kilometers\n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2      \n",
    "    return 12734 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "#Similarity location\n",
    "def simi_location(distance):\n",
    "    return 1/(1+100 * distance * distance)\n",
    "\n",
    "\n",
    "# Calcula la similitud entre dos strings usando leventein\n",
    "def simi_levenshtein(s1, s2):\n",
    "    if len(s2) == 0 or len(s1) == 0:\n",
    "        return 0    \n",
    "    if s1 == s2:\n",
    "        return 1\n",
    "    return 1-(jf.levenshtein_distance(s1,s2)/max(len(s1),len(s2)))\n",
    "\n",
    "# # Calcula la similitud entre dos strings usando leventein\n",
    "# def simi_levenshtein(s1, s2):\n",
    "#     if len(s2) == 0 or len(s1) == 0:\n",
    "#         return 0    \n",
    "#     if s1 == s2:\n",
    "#         return 1\n",
    "#     return 1-(jf.levenshtein_distance(s1,s2)/max(len(s1),len(s2)))\n",
    "\n",
    "\n",
    "# Similarity distance\n",
    "def simi_stars(star1,star2):\n",
    "    if math.isnan(star1) or math.isnan(star2):\n",
    "        d = 9999\n",
    "    else:\n",
    "        d = star1 - star2\n",
    "    #Como la potencia es par no saco valor absoluto !!!        \n",
    "    return 1/(1+d**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitud maxima = 31\n",
      "Leventein= 16\n",
      "demerau= 16\n",
      "hamming= 16\n",
      "jaro = 0.8279569892473119\n",
      "jaro winkler= 0.8967741935483872\n",
      "0.4838709677419355\n"
     ]
    }
   ],
   "source": [
    "s1= 'no. 109 wenyuan east street'\n",
    "s2=\t'no. 188 grand west street'\n",
    "s1= 'no. 109 wenyuan east '\n",
    "s2=\t'no. 188 grand west '\n",
    "\n",
    "s1= 'rua bambuzal 21 praia de geriba'\n",
    "s2=\t'rua bambuzal 21'\n",
    "\t\t\n",
    "\n",
    "print('longitud maxima =',max(len(s1),len(s2)))\n",
    "print('Leventein=',jf.levenshtein_distance(s1,s2))\n",
    "print('demerau=',jf.damerau_levenshtein_distance(s1,s2))\n",
    "print('hamming=',jf.hamming_distance(s1,s2))\n",
    "print('jaro =',jf.jaro_similarity(s1,s2))\n",
    "print('jaro winkler=',jf.jaro_winkler_similarity(s1,s2))\n",
    "print(simi_levenshtein(s1,s2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates['loc_distance'] = haversine_np(candidates['lng_x'],candidates['lat_x'],candidates['lng_y'],candidates['lat_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates['propertyname_sim'] = candidates.apply(lambda x: simi_levenshtein(x['propertyname_x'],x['propertyname_y']),axis=1, meta=(None, 'float32')).astype(np.float32)\n",
    "candidates['address_sim'] = candidates.apply(lambda x: simi_levenshtein(x['address_x'],x['address_y']),axis=1, meta=(None, 'float32')).astype(np.float32)\n",
    "candidates['loc_sim'] = candidates.apply(lambda x: simi_location(x['loc_distance']),axis=1, meta=(None, 'float32')).astype(np.float32) \n",
    "candidates['city_sim'] = candidates.apply(lambda x: simi_levenshtein(x['city_x'],x['city_y']),axis=1, meta=(None, 'float32')).astype(np.float32)\n",
    "candidates['starrating_sim'] = candidates.apply(lambda x: simi_stars(x['starrating_x'],x['starrating_y']),axis=1, meta=(None, 'float32')).astype(np.float32)\n",
    "candidates['state_sim'] = candidates.apply(lambda x: simi_levenshtein(x['state_x'],x['state_y']),axis=1, meta=(None, 'float32')).astype(np.float32)\n",
    "candidates['zipcode_sim'] = candidates.apply(lambda x: simi_levenshtein(x['zipcode_x'],x['zipcode_y']),axis=1, meta=(None, 'float32')).astype(np.float32)\n",
    "candidates['email_sim'] = candidates.apply(lambda x: simi_levenshtein(x['email_x'],x['email_y']),axis=1, meta=(None, 'float32')).astype(np.float32)\n",
    "candidates['phone_sim'] =  candidates.apply(lambda x: simi_levenshtein(x['phone_x'],x['phone_y']),axis=1, meta=(None, 'float32')).astype(np.float32)\n",
    "candidates['fax_sim'] = candidates.apply(lambda x: simi_levenshtein(x['fax_x'],x['fax_y']),axis=1, meta=(None, 'float32')).astype(np.float32)\n",
    "candidates['website_sim'] = candidates.apply(lambda x: simi_levenshtein(x['website_x'],x['website_y']),axis=1, meta=(None, 'float32')).astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\bin\\anaconda3\\envs\\mapping\\lib\\site-packages\\dask\\dataframe\\core.py:7506: UserWarning: Insufficient elements for `head`. 20 elements requested, only 0 elements available. Try passing larger `npartitions` to `head`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyId</th>\n",
       "      <th>providerid</th>\n",
       "      <th>PropertyByProviderId</th>\n",
       "      <th>countrycorregido_x</th>\n",
       "      <th>countrycorregido_y</th>\n",
       "      <th>propertytype_x</th>\n",
       "      <th>propertytype_y</th>\n",
       "      <th>propertyname_x</th>\n",
       "      <th>propertyname_y</th>\n",
       "      <th>propertyname_sim</th>\n",
       "      <th>lat_x</th>\n",
       "      <th>lat_y</th>\n",
       "      <th>lng_x</th>\n",
       "      <th>lng_y</th>\n",
       "      <th>loc_distance</th>\n",
       "      <th>loc_sim</th>\n",
       "      <th>address_x</th>\n",
       "      <th>address_y</th>\n",
       "      <th>address_sim</th>\n",
       "      <th>zipcode_y</th>\n",
       "      <th>zipcode_x</th>\n",
       "      <th>zipcode_sim</th>\n",
       "      <th>city_x</th>\n",
       "      <th>city_y</th>\n",
       "      <th>city_sim</th>\n",
       "      <th>state_y</th>\n",
       "      <th>state_x</th>\n",
       "      <th>state_sim</th>\n",
       "      <th>starrating_y</th>\n",
       "      <th>starrating_x</th>\n",
       "      <th>starrating_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PropertyId, providerid, PropertyByProviderId, countrycorregido_x, countrycorregido_y, propertytype_x, propertytype_y, propertyname_x, propertyname_y, propertyname_sim, lat_x, lat_y, lng_x, lng_y, loc_distance, loc_sim, address_x, address_y, address_sim, zipcode_y, zipcode_x, zipcode_sim, city_x, city_y, city_sim, state_y, state_x, state_sim, starrating_y, starrating_x, starrating_sim]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols2 = [\n",
    "    'PropertyId',\n",
    "    'providerid',\n",
    "    'PropertyByProviderId',\n",
    "    'countrycorregido_x',\n",
    "    'countrycorregido_y',\n",
    "    'propertytype_x',\n",
    "    'propertytype_y',\n",
    "    'propertyname_x',\n",
    "    'propertyname_y',\n",
    "    'propertyname_sim',\n",
    "    'lat_x',\n",
    "    'lat_y',\n",
    "    'lng_x',\n",
    "    'lng_y',\n",
    "    'loc_distance',\n",
    "    'loc_sim',\n",
    "    'address_x',\n",
    "    'address_y',\n",
    "    'address_sim',\n",
    "    'zipcode_y',\n",
    "    'zipcode_x',\n",
    "    'zipcode_sim',\n",
    "    'city_x',\n",
    "    'city_y',\n",
    "    'city_sim',\n",
    "    'state_y',\n",
    "    'state_x',\n",
    "    'state_sim',\n",
    "    'starrating_y',\n",
    "    'starrating_x',\n",
    "    'starrating_sim'\n",
    "    \n",
    "    \n",
    "    \n",
    "    ]\n",
    "candidates.loc[(candidates.providerid == 'NTP') ].head(20)[cols2]\n",
    "\n",
    "#& (candidates.loc_sim > .1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EXP     262792\n",
       "HBD      29130\n",
       "EXPS         1\n",
       "Name: providerid, dtype: Int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates.providerid.value_counts().compute( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#candidates[candidates.loc_distance > 0.5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cand['propertyname_sim'] = cand.apply(lambda x: 1-jellyfish.levenshtein_distance(x['propertyname_x'],x['propertyname_y'])/max([len(x['propertyname_x']), len(x['propertyname_y'])]),axis=1).astype(np.float32)\n",
    "#cand.head()[['propertyname_x', 'propertyname_y', 'propertyname_sim']]\n",
    "#candidates.head()[['propertyname_x', 'propertyname_y', 'propertyname_sim']]\n",
    "\n",
    "#cand['address_sim'] = cand.apply(lambda x: 1-jellyfish.levenshtein_distance(x['address_x'],x['address_y'])/max([len(x['address_x']), len(x['propertyname_y'])]),axis=1).astype(np.float32)\n",
    "#cand.head(50)[['address_x', 'address_y', 'address_sim']]\n",
    "#candidates.head()[['address_x', 'address_y', 'address_sim']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
