{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x203026f0d30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import html\n",
    "import re\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import strip_accents_ascii, strip_accents_unicode\n",
    "\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "numcores = 16\n",
    "tiene_gpu = False\n",
    "pd.set_option('display.max_columns', 99)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "\n",
    "#dask.config.set(scheduler='processes')  \n",
    "dask.config.set(scheduler='threads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este es el root en el servidor de jupyter\n",
    "data_root = 'C:/code/hotelmapping/data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Clean function for String Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CleanStringCol(col_serie, encoding='utf-8', decode_error='strict', replace_by_none=r'[^ \\-\\_A-Za-z0-9ñÑ]+', remove_brackets=True, replace_by_whitespace=r'[\\-\\_]', IsDask: bool = True):\n",
    "    # Decode Strings\n",
    "    col_serie = col_serie.map(lambda x: x.decode(encoding, decode_error) if type(x) == bytes else x)        \n",
    "    # unescape html string in col_serie\n",
    "    col_serie = col_serie.map(lambda x: html.unescape(x))\n",
    "    # To lowercase\n",
    "    col_serie = col_serie.str.lower()\n",
    "    \n",
    "    # Remove  accents from unicode strings\n",
    "    if IsDask:        \n",
    "        col_serie = col_serie.map(lambda x: strip_accents_unicode(x) ,meta=(None, 'string')   )\n",
    "    else:\n",
    "        col_serie = col_serie.map(lambda x: strip_accents_unicode(x) )\n",
    "        \n",
    "    # Remove all content between brackets\n",
    "    if remove_brackets:\n",
    "        col_serie = col_serie.str.replace(r'(\\[.*?\\]|\\(.*?\\)|\\{.*?\\})', '')\n",
    "    #Reemplaza por espacios algunos simbolos \n",
    "    col_serie = col_serie.str.replace(replace_by_whitespace, ' ')\n",
    "    #Saca los símbolos permitidos\n",
    "    col_serie = col_serie.str.replace(replace_by_none, '')\n",
    "    # Remove multiple whitespaces\n",
    "    col_serie = col_serie.str.replace(r'\\s\\s+', ' ')\n",
    "    # Strip \n",
    "    col_serie = col_serie.str.lstrip().str.rstrip()\n",
    "    return col_serie\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex (caracteres para eliminar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_regex=r'[^ \\-\\_\\.@#\\/&ñÑA-Za-z0-9]+'\n",
    "website_regex=r'[^\\-\\.\\/%?&A-Za-z0-9]+'\n",
    "phone_regex = r'[^0-9]+' \n",
    "email_regex = r'[^\\-\\_\\.@A-Za-z0-9]+'\n",
    "\n",
    "# Otra phone_regex para revisar ([^\\-\\+\\.()0-9]+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geonames (pandas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryinfo_file = os.path.join(data_root, 'geo/countryinfo.csv')\n",
    "df_countryinfo = pd.read_csv(countryinfo_file,sep='\\t',low_memory=False,infer_datetime_format=True, keep_default_na = False)\n",
    "df_country = df_countryinfo[['Country','ISO','ISO3','fips']].drop_duplicates().set_index('ISO')\n",
    "df_country['countrycorregido'] = CleanStringCol(df_country['Country'],IsDask=False)\n",
    "# df_country.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_country.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_file = os.path.join(data_root, 'travcoding/Properties.parquet')\n",
    "inventory_ddf = dd.read_parquet(inventory_file, engine='pyarrow' ).set_index('PropertyId').repartition(npartitions=numcores)\n",
    "\n",
    "# Completa el rating\n",
    "inventory_ddf.StarRating = inventory_ddf.StarRating.fillna('0')\n",
    "\n",
    "# Corrige los tipos de datos\n",
    "inventory_ddf = inventory_ddf.astype({\n",
    "    'nameshort': 'string', \n",
    "    'namefull' : 'string', \n",
    "    'propertytype': 'string',\n",
    "    'latitud' : 'float32',\n",
    "    'longitud' : 'float32',\n",
    "    'Address' : 'string',\n",
    "    'ZipCode' : 'string',\n",
    "    'CityCode' : 'string',\n",
    "    'City' : 'string',\n",
    "    'StateCode' : 'string',\n",
    "    'State': 'string',\n",
    "    'CountryCode' : 'string',\n",
    "    'Country' : 'string',\n",
    "    'Email' : 'string',\n",
    "    'Phone' : 'string',\n",
    "    'Fax' : 'string',\n",
    "    'Website' : 'string',\n",
    "    'StarRating' : 'int32'\n",
    "})\n",
    "\n",
    "inventory_ddf = inventory_ddf.rename(columns={\n",
    "    'latitud' : 'lat',\n",
    "    'longitud': 'lng',\n",
    "    'Address' : 'address',\n",
    "    'ZipCode' : 'zipcode',\n",
    "    'City'    : 'city',\n",
    "    'State'   : 'state',\n",
    "    'Country' : 'country',\n",
    "    'Email'   : 'email',\n",
    "    'Phone'   : 'phone',\n",
    "    'Fax'     : 'fax',\n",
    "    'Website' : 'website',\n",
    "    'StarRating' : 'starrating',\n",
    "    'CountryCode' : 'countrycode'    \n",
    "})  \n",
    "\n",
    "#inventory_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inventory_ddf.index.size.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inventory_ddf.address.to_csv(os.path.join(data_root, 'travcoding/address.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country\n",
    "inventory_ddf['countrycode'] = inventory_ddf['countrycode'].fillna('')\n",
    "inventory_ddf['countrycorregido'] = inventory_ddf.merge(df_country, left_on='countrycode', right_index=True , how=\"left\")['countrycorregido'].fillna('').compute()\n",
    "inventory_ddf['countrycorregido'] = inventory_ddf['countrycorregido'].where(inventory_ddf['countrycorregido'] > '',  inventory_ddf['country'].fillna('') )\n",
    "inventory_ddf['countrycorregido'] = CleanStringCol(inventory_ddf['countrycorregido'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inventory_ddf.index.size.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completa la latitud y longitud\n",
    "inventory_ddf.lat = inventory_ddf.lat.fillna(9999)\n",
    "inventory_ddf.lng = inventory_ddf.lng.fillna(9999)\n",
    "\n",
    "\n",
    "# Completa el rating\n",
    "inventory_ddf.starrating = inventory_ddf.starrating.fillna('0')\n",
    "\n",
    "\n",
    "# propertyname\n",
    "inventory_ddf['propertyname'] = CleanStringCol(inventory_ddf['namefull']).fillna('')\n",
    "\n",
    "\n",
    "#propertytype\n",
    "inventory_ddf['propertytype'] = CleanStringCol(inventory_ddf['propertytype']).fillna('')\n",
    "\n",
    "\n",
    "# email\n",
    "inventory_ddf['email'] = CleanStringCol(inventory_ddf['email'].fillna(''),replace_by_none=email_regex).fillna('')\n",
    "\n",
    "\n",
    "# phone y fax\n",
    "inventory_ddf['phone'] = CleanStringCol(inventory_ddf['phone'].fillna(''),replace_by_none=phone_regex).fillna('')\n",
    "inventory_ddf['fax'] = CleanStringCol(inventory_ddf['fax'].fillna(''),replace_by_none=phone_regex).fillna('')\n",
    "\n",
    "\n",
    "# website\n",
    "inventory_ddf['website'] = CleanStringCol(inventory_ddf['website'].fillna(''),replace_by_none=website_regex).fillna('')\n",
    "\n",
    "# State\n",
    "inventory_ddf['state'] = CleanStringCol(inventory_ddf['state'].fillna('')).fillna('')\n",
    "\n",
    "# zipcode\n",
    "inventory_ddf['zipcode'] = CleanStringCol(inventory_ddf['zipcode'].fillna('')).fillna('')\n",
    "\n",
    "# adress\n",
    "inventory_ddf['address'] = CleanStringCol(inventory_ddf['address'].fillna(''),replace_by_none=address_regex, remove_brackets=True).fillna('')\n",
    "\n",
    "# city\n",
    "inventory_ddf['city'] = CleanStringCol(inventory_ddf['city'].fillna('')).fillna('')\n",
    "\n",
    "# Drop unused columns\n",
    "inventory_ddf = inventory_ddf.drop(columns=['nameshort', 'namefull', 'CityCode', 'StateCode', 'country'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inventory_ddf.index.size.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inventory_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inventory_clean_file = os.path.join(data_root, 'travcoding/properties_clean.parquet')\n",
    "inventory_ddf.to_parquet(inventory_clean_file, engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "providers_file = os.path.join(data_root, 'travcoding/PropertiesByProvider.parquet')\n",
    "providers_ddf = dd.read_parquet(providers_file, engine ='pyarrow' ).set_index('PropertyByProviderId').repartition(npartitions=numcores)\n",
    "\n",
    "providers_ddf['starrating'] = providers_ddf['starrating'].fillna('0')\n",
    "providers_ddf['starrating'] = providers_ddf['starrating'].replace({\n",
    "    'null':'0',\n",
    "    '0.0' : '0',\n",
    "    '1.0' : '1',\n",
    "    '1.5' : '1',\n",
    "    '2.0' : '2',\n",
    "    '2.5' : '2',\n",
    "    '3.0' : '3',\n",
    "    '3.5' : '3',\n",
    "    '4.0' : '4',\n",
    "    '4.5' : '4',\n",
    "    '5.0' : '5',\n",
    "    '5.5' : '5',\n",
    "    '6.0' : '6'\n",
    "    } )\n",
    "\n",
    "providers_ddf['lat'] = providers_ddf['lat'].replace({'null':'9999'} )\n",
    "providers_ddf['lng'] = providers_ddf['lng'].replace({'null':'9999'} )\n",
    "\n",
    "providers_ddf = providers_ddf.astype({\n",
    "    'ProviderId': 'string',\n",
    "    #'PropertyByProviderId': 'int32',\n",
    "    'propertytype': 'string',\n",
    "    'name' : 'string',\n",
    "    'lat' : 'float32',\n",
    "    'lng' : 'float32',\n",
    "    'address' : 'string',\n",
    "    'zipcode' : 'string',\n",
    "    'citycode' : 'string',\n",
    "    'cityname' : 'string',\n",
    "    'statecode' : 'string',\n",
    "    'statename' : 'string',\n",
    "    'countrycode' : 'string',\n",
    "    'countryname' : 'string',\n",
    "    'email' : 'string',\n",
    "    'phone' : 'string',\n",
    "    'fax' : 'string',\n",
    "    'website' : 'string',\n",
    "    'starrating' : 'int32'\n",
    "})\n",
    "\n",
    "providers_ddf = providers_ddf.rename(columns={\n",
    "    'cityname'      : 'city',\n",
    "    'statename'     : 'state',\n",
    "    'countryname'   : 'country',\n",
    "    'Language'      : 'language',\n",
    "    'ProviderId'    : 'providerid',\n",
    "    'PropertyId'    : 'propertyid'\n",
    "})  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'name', \n",
    "providers_ddf['name'] = providers_ddf['name'].fillna('')\n",
    "providers_ddf['propertyname'] = CleanStringCol(providers_ddf['name'])\n",
    "\n",
    "\n",
    "# State\n",
    "providers_ddf['state'] = CleanStringCol(providers_ddf['state'].fillna('')).fillna('')\n",
    "\n",
    "#city\n",
    "providers_ddf['city'] = CleanStringCol(providers_ddf['city'].fillna('')).fillna('')\n",
    "\n",
    "\n",
    "# 'country_corregido',\n",
    "providers_ddf['countrycode'] = providers_ddf['countrycode'].fillna('')\n",
    "providers_ddf['countrycorregido'] = providers_ddf.merge(df_country, left_on='countrycode', right_index=True , how=\"left\")['countrycorregido'].fillna('').compute()\n",
    "providers_ddf['countrycorregido']= providers_ddf['countrycorregido'].where(providers_ddf['countrycorregido'] > '',  providers_ddf['country'].fillna('') )\n",
    "providers_ddf['countrycorregido'] = CleanStringCol(providers_ddf['countrycorregido'])\n",
    "\n",
    "#propertytype\n",
    "providers_ddf['propertytype'] = CleanStringCol(providers_ddf['propertytype'].fillna(''))\n",
    "\n",
    "\n",
    "# email\n",
    "providers_ddf['email'] = CleanStringCol(providers_ddf['email'].fillna(''),replace_by_none=email_regex).fillna('')\n",
    "\n",
    "\n",
    "# phone y fax\n",
    "providers_ddf['phone'] = CleanStringCol(providers_ddf['phone'].fillna(''),replace_by_none=phone_regex).fillna('')\n",
    "providers_ddf['fax'] = CleanStringCol(providers_ddf['fax'].fillna(''),replace_by_none=phone_regex).fillna('')\n",
    "\n",
    "\n",
    "# website\n",
    "providers_ddf['website'] = CleanStringCol(providers_ddf['website'].fillna(''),replace_by_none=website_regex).fillna('')\n",
    "\n",
    "\n",
    "# property_type\n",
    "providers_ddf['propertytype'] = providers_ddf['propertytype'].where(providers_ddf['propertytype'].notnull(),  providers_ddf['propertytype2'].fillna('') )\n",
    "\n",
    "\n",
    "# address\n",
    "providers_ddf['address'] = CleanStringCol(providers_ddf['address'].fillna(''),replace_by_none=address_regex,remove_brackets=True).fillna('')\n",
    "\n",
    "#zipcode\n",
    "providers_ddf['zipcode'] = CleanStringCol(providers_ddf['zipcode'].fillna('')).fillna('')\n",
    "\n",
    "\n",
    "providers_ddf = providers_ddf.drop(columns=[ 'propertytype2', 'citycode', 'statecode', 'country','name','propertyid2' ])  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#providers_ddf.providerid.value_counts().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "providers_clen_file = os.path.join(data_root, 'travcoding/providers_clean.parquet')\n",
    "providers_ddf.to_parquet(providers_clen_file, engine ='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otras pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para hacer pruebas lo convierto a pandas\n",
    "\n",
    "# inventory_pdf = inventory_ddf.compute()\n",
    "# providers_pdf = providers_ddf.compute()\n",
    "# p1= providers_pdf\n",
    "# p1[p1.country_corregido == ''].countrycode.unique()\n",
    "\n",
    "# #['NA', 'UK', 'NY', 'C0', 'SF', 'BK', 'KV', '']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['UK', 'NY', 'C0', 'SF', 'BK', 'KV', '']\n",
    "#UK --> GB\n",
    "#NY --> \n",
    "#C0 --> \n",
    "#SF --> ZA\n",
    "#BK --> BA\n",
    "#KV --> XK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freceunace ade caracteres\n",
    "# char_frec = p1.address.fillna(' ').str.split().explode().apply(lambda x: list(str(x))).explode().value_counts()\n",
    "# char_frec.to_csv('data/travcoding/char_frec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (hh:mm:ss.ms) 0:02:39.980190\n"
     ]
    }
   ],
   "source": [
    "time_elapsed = datetime.now() - start_time\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4589a0a38e08316dddfe24a3a427e7d98888b5a95aab4e49f18b602f67c670d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
