{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import pandas as pd\n",
    "import html\n",
    "import re\n",
    "from sklearn.feature_extraction.text import strip_accents_ascii, strip_accents_unicode\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "numcores = 16\n",
    "tiene_gpu = False\n",
    "pd.set_option('display.max_columns', 99)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "import os \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# Este es el root en el servidor de jupyter\n",
    "data_root = 'C:/code/hotelmapping/data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deshabilito los future wanings ya que se resolverá en el futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargo datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_clean_file = os.path.join(data_root, 'travcoding/Properties_clean.parquet')\n",
    "providers_clean_file = os.path.join(data_root, 'travcoding/Providers_clean.parquet')\n",
    "\n",
    "# Cargo los archivos\n",
    "inventory_ddf = dd.read_parquet(properties_clean_file, engine='pyarrow')\n",
    "provider_ddf  = dd.read_parquet(providers_clean_file, engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Providers =\",provider_ddf.index.size.compute())\n",
    "# print(\"Inventaory =\",inventory_ddf.index.size.compute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genero las estadisticas de las palabras de la columna del nombre de la propiedad y de cada registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_word_stats(ddf, colum_name,key_name):            \n",
    "    ddf1 = ddf[colum_name].str.split().explode()\n",
    "    ddf2 = ddf1.value_counts().reset_index().rename(columns={'index': 'word',colum_name:'cantidad'})                           \n",
    "    ddf2['freq'] = (ddf2.cantidad/ddf2.cantidad.sum())\n",
    "    ddf2['idf']  = (da.log(1/ddf2.freq))\n",
    "    ddf3= ddf1.to_frame().reset_index().merge(ddf2, how='left', left_on=colum_name, right_on='word')[[key_name,'idf']]\n",
    "    ddf4=ddf3.groupby(by=[key_name]).agg({'idf': ['count','sum','max','mean'] }).reset_index()\n",
    "    ddf4.columns = [\"_\".join(x) for x in ddf4.columns.ravel()]\n",
    "    ddf4 = ddf4.rename(columns={(key_name+'_'): key_name}).set_index(key_name)    \n",
    "    return ddf2, ddf4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventory word stats =  193628\n",
      "Inventory property name stats = 523935\n"
     ]
    }
   ],
   "source": [
    "column_name = 'propertyname'\n",
    "keycol_name = 'PropertyId'\n",
    "inventory_words_stats_ddf, inventory_propertyname_stats_ddf = get_word_stats(inventory_ddf, column_name, keycol_name)\n",
    "\n",
    "print (\"Inventory word stats = \",inventory_words_stats_ddf.index.size.compute())\n",
    "print(\"Inventory property name stats =\", inventory_propertyname_stats_ddf.index.size.compute())\n",
    "#inventory_propertyname_stats_ddf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider word stats =  204948\n",
      "Provider property name stats = 703021\n"
     ]
    }
   ],
   "source": [
    "\n",
    "column_name = 'propertyname'\n",
    "keycol_name = 'PropertyByProviderId'\n",
    "provider_words_stats_ddf, provider_propertyname_stats_ddf = get_word_stats(provider_ddf, column_name, keycol_name)\n",
    "\n",
    "\n",
    "print (\"Provider word stats = \",provider_words_stats_ddf.index.size.compute())\n",
    "print(\"Provider property name stats =\", provider_propertyname_stats_ddf.index.size.compute())\n",
    "#provider_propertyname_stats_ddf.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inventory_propertyname_stats_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genera Stopwords y Regex de stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Devuelve una lista con los stopwords a partir del df de estadisticas\n",
    "def get_stopwords_list(word_stats_ddf,cantidad_minima):\n",
    "    stopwords = []\n",
    "    for stopword in word_stats_ddf[word_stats_ddf.cantidad>cantidad_minima].word:\n",
    "        stopwords.append(stopword.rstrip('\\n').lower())    \n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Stopwords = 927\n",
      "#  palabras total = 193628\n"
     ]
    }
   ],
   "source": [
    "cantidad_minima = 200\n",
    "property_name_stopwords = get_stopwords_list(inventory_words_stats_ddf,cantidad_minima)\n",
    "property_name_stopwords_regex = re.compile(r'\\b(' + r'|'.join(property_name_stopwords) + r')\\b')\n",
    "\n",
    "print(\"# Stopwords =\",len(property_name_stopwords))\n",
    "print(\"#  palabras total =\", len(inventory_words_stats_ddf.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Stopwords\n",
    "#Inventory_words_stats[Inventory_words_stats.cantidad>cantidad_minima].compute().sort_values('cantidad', ascending=False).to_csv('data/travcoding/stopwords.csv') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocking\n",
    "\n",
    "## BUGS\n",
    "Hayq ue revisar esta función porque devuelve menos registros que la tabla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blocking_df( data_ddf, \n",
    "                blocking_column, \n",
    "                stopwords_regex, \n",
    "                aditional_blocking_column='countrycorregido'):       \n",
    "    return data_ddf[blocking_column].str.replace(stopwords_regex,'').str.split().explode().dropna()\\\n",
    "        .to_frame().rename(columns={ blocking_column :  'value'})\\\n",
    "        .merge(data_ddf, left_index=True, right_index=True)[['value', aditional_blocking_column]].reset_index().drop_duplicates()\n",
    "        #.compute()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocking_column = 'propertyname'    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genera indice para el inventario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#property_name_stopwords_regex\n",
    "inv_indx_ddf = get_blocking_df(inventory_ddf,blocking_column,property_name_stopwords_regex)\n",
    "#inv_indx = inv_indx.reset_index()\n",
    "# print(\"Inventory  = \", inventory_ddf.index.size.compute())\n",
    "# print(\"Index rows = \", inv_indx_ddf.index.size.compute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genera indice para proveedores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prv_indx_ddf = get_blocking_df(provider_ddf,blocking_column,property_name_stopwords_regex)\n",
    "#print(\"Index rows = \", prv_indx_ddf.index.size.compute())\n",
    "#prv_indx_ddf.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genera candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arma las combinaciones de los indices\n",
    "candidates_ddf = dd.merge(inv_indx_ddf, prv_indx_ddf, how='inner', left_on=['value','countrycorregido'], right_on=['value','countrycorregido']).repartition(npartitions=16)\n",
    "\n",
    "# Agrega la sestadistica de palabras\n",
    "candidates_ddf = candidates_ddf.merge(inventory_words_stats_ddf, how='left', left_on='value', right_on='word')\n",
    "\n",
    "# Agrego candidad de palabras y suma de IDF\n",
    "candidates_ddf = candidates_ddf.groupby(['PropertyId','PropertyByProviderId']).agg({'idf': ['count','sum','max','mean'] }).reset_index().repartition(npartitions=16)\n",
    "\n",
    "#Aplano los niveles del multiindex\n",
    "candidates_ddf.columns = [\"_\".join([z.strip() for z in x if z.strip()]) for x in candidates_ddf.columns.ravel()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#candidates_ddf.index.size.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates_ddf = candidates_ddf.sort_values('idf_sum',ascending=False)\n",
    "# candidates_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#inventory_ddf.loc['739246'].compute()\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provider_ddf.loc['468971'].compute()\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabo los candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path a los archivos\n",
    "pair_candidates_file = os.path.join(data_root, 'travcoding/pair_candidates.parquet')    \n",
    "candidates_ddf.to_parquet(pair_candidates_file, engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair_candidates2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "filename = os.path.join(data_root, 'travcoding/addresslong.csv')    \n",
    "# candidates_pd.head(10000)[['address_x','address_y']].to_csv(filename,header=False, sep=\"\\t\", encoding='utf-8',quotechar='\"', quoting=csv.QUOTE_ALL, index=None)  \n",
    "\n",
    "\n",
    "# filename = os.path.join(data_root, 'travcoding/propertylong.csv')    \n",
    "# candidates_pd.head(10000)[['propertyname_x','propertyname_y']].to_csv(filename,header=False, sep=\"\\t\", encoding='utf-8',quotechar='\"', quoting=csv.QUOTE_ALL, index=None)  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (hh:mm:ss.ms) 0:01:13.575175\n"
     ]
    }
   ],
   "source": [
    "time_elapsed = datetime.now() - start_time\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4589a0a38e08316dddfe24a3a427e7d98888b5a95aab4e49f18b602f67c670d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
